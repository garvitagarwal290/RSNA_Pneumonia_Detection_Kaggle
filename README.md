# Description

This is my implementation of a pneumonia detection model for X-ray scans of the lungs. It is based on Kaggle's [RSNA Pneumonia Detection Challenge](https://www.kaggle.com/competitions/rsna-pneumonia-detection-challenge/overview) competition. My implementation takes inspiration from the discussions among the winners of the competition [here](https://www.kaggle.com/competitions/rsna-pneumonia-detection-challenge/discussion?sort=hotness).

# Details

1) I used this [Retinanet detection model](https://github.com/yhenon/pytorch-retinanet) implementation to start with.

modifications: augmentation, ensemble

dropout

image size

detection parameters: all thresholds





Taking the option with the highest score as the model's `answer', the above model answered only 63 questions correctly out of 200. This accuracy is not significantly more than a model that chooses an option randomly out of the 5 options. The sub-par performance might be due to the following reasons:

1) **_Limited GPU resources:_** All the above steps were implemented on Kaggle and so were subjected to the GPU memory and time limitations. This limited the size of the answering/reader model.
2) **_Limited context length:_** The maximum context length of our reader model was 512 tokens. This is likely not enough to accommodate many long Wikipedia articles which are hence truncated. The truncation might result in the loss of essential context required to answer the question. Hence an encoder model with a larger context length should perform better, however, at the same time, the limited GPU memory might cause a roadblock.
3) **_Limited Wikipedia dataset:_** Though our Wikipedia dataset had 130k articles, the test questions are supposed to be difficult questions generated by GPT3.5. It was seen that for many test questions, the Wikipedia article identified by our retrieval model did not actually have the information required to answer the question. Hence a bigger retrieval dataset should improve performance.

To conclude, more work is required to build a more accurate RAG-based MCQ answering model.

